{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Роли в промптах\n",
    "\n",
    "## Обзор\n",
    "\n",
    "В этом ноутбуке рассматривается концепция ролевого программирования в языковых моделях — как назначать модели конкретную роль и составлять эффективные описания ролей. Для демонстрации мы будем использовать GPT-модели OpenAI и библиотеку LangChain.\n",
    "\n",
    "## Мотивация\n",
    "\n",
    "Ролевое программирование — это мощная техника инженерии промптов, позволяющая направлять языковую модель на определённую «персону» или область экспертизы. Это может значительно повысить качество и релевантность её ответов для специализированных задач.\n",
    "\n",
    "## Ключевые компоненты\n",
    "\n",
    "1. **Назначение роли:** приёмы для задания роли языковой модели.\n",
    "2. **Формулировка описания роли:** как составить качественное и подробное описание.\n",
    "3. **Задание контекста:** как давать модели необходимую вводную для роли.\n",
    "4. **Формулировка задачи:** как чётко объяснить, что требуется от модели в данной роли."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Установка окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(os.path.join(os.path.dirname(os.getcwd()), \".env\"))\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "base_url = os.getenv('BASE_URL')\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", base_url=base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Базовое назначение роли\n",
    "\n",
    "Давайте начнём с простого примера назначения роли. Мы создадим промпт, который назначает модели роль технического писателя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_writer_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"\"\"Вы — методист, специализирующийся на создании понятных и лаконичных учебных материалов для образовательных курсов в сфере ИТ.\n",
    "Ваша задача — написать краткое объяснение понятия «{topic}» для обучающего пособия.\n",
    "Сформулируйте объяснение в 2–3 простых предложениях, чтобы это было понятно новичкам без технической подготовки.\"\"\"\n",
    ")\n",
    "\n",
    "chain = tech_writer_prompt | llm\n",
    "response = chain.invoke({\"topic\": \"облачные вычисления\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как создавать эффективные описания ролей\n",
    "\n",
    "Давайте разберёмся, как формулировать более подробные и эффективные описания ролей. Мы создадим промпт для роли финансового консультанта с расширенным описанием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_specialist_prompt = PromptTemplate(\n",
    "    input_variables=[\"student_context\"],\n",
    "    template=\"\"\"Вы — опытный методист с более чем 20-летним стажем в области образования и разработки учебных программ.\n",
    "Вы помогаете ученикам с разным уровнем подготовки достигать учебных целей, делая сложные темы доступными.\n",
    "Ваш подход включает в себя:\n",
    "1. Внимательный анализ индивидуальных особенностей и уровня ученика\n",
    "2. Ясное и простое объяснение даже сложных понятий\n",
    "3. Заботу об этике и поддерживающей атмосфере\n",
    "4. Акцент на долгосрочное понимание и самостоятельное мышление\n",
    "\n",
    "Изучите следующую ситуацию ученика и дайте краткую (3-4 предложения) рекомендацию или совет:\n",
    "{student_context}\n",
    "\n",
    "Ваш ответ должен отражать ваш профессионализм и придерживаться описанного подхода.\"\"\"\n",
    ")\n",
    "\n",
    "chain = education_specialist_prompt | llm\n",
    "response = chain.invoke({\"student_context\": \"Ученик 8 класса испытывает трудности с пониманием основ алгебры, несмотря на старание и выполнение домашних заданий.\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение ответов с разными ролями\n",
    "\n",
    "Чтобы продемонстрировать, как разные роли влияют на ответы ИИ, давайте создадим промпты для трёх разных ролей и сравним их выводы на одну и ту же тему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = [\n",
    "    (\"Научный сотрудник\", \"Вы — исследователь в области педагогики и образовательных технологий. Объясните следующий термин с научной точки зрения:\"),\n",
    "    (\"Учитель\", \"Вы — школьный учитель, который объясняет материал ученикам 7 класса. Объясните следующий термин простыми словами, чтобы было понятно подросткам:\"),\n",
    "    (\"Журналист\", \"Вы — журналист, пишущий для популярного образовательного журнала. Объясните следующий термин понятно и интересно для широкой взрослой аудитории:\")\n",
    "]\n",
    "\n",
    "topic = \"Формирующее оценивание\"\n",
    "\n",
    "for role, description in roles:\n",
    "    role_prompt = PromptTemplate(\n",
    "        input_variables=[\"topic\"],\n",
    "        template=f\"{description} {{topic}}\"\n",
    "    )\n",
    "    chain = role_prompt | llm\n",
    "    response = chain.invoke({\"topic\": topic})\n",
    "    print(f\"\\nОбъяснение роли: {role}\\n\")\n",
    "    print(response.content)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Улучшаем описание ролей\n",
    "\n",
    "Давайте рассмотрим, как уточнение ролей задаёт более специфичный результат. В качестве примера используем креативное письмо с разными стилями повествования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_prompt = PromptTemplate(\n",
    "    input_variables=[\"style\", \"scenario\"],\n",
    "    template=\"\"\"Вы — выдающийся педагог, умеющий доносить материал в самых разных стилях преподавания.\n",
    "Ваша задача — объяснить учебную ситуацию в стиле: {style}.\n",
    "Ключевые особенности этого стиля:\n",
    "1. {style_char1}\n",
    "2. {style_char2}\n",
    "3. {style_char3}\n",
    "\n",
    "Напишите краткое объяснение (3–4 предложения) в этом стиле по следующей образовательной ситуации:\n",
    "{scenario}\n",
    "\n",
    "Ваш текст должен чётко отражать выбранный стиль объяснения.\"\"\"\n",
    ")\n",
    "\n",
    "styles = [\n",
    "    {\n",
    "        \"name\": \"Доброжелательный наставник\",\n",
    "        \"char1\": \"Тёплая и поддерживающая манера\",\n",
    "        \"char2\": \"Упор на веру в возможности ученика\",\n",
    "        \"char3\": \"Побуждение не бояться ошибок\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Строгий классический учитель\",\n",
    "        \"char1\": \"Чёткая и структурированная подача\",\n",
    "        \"char2\": \"Акцент на дисциплине и порядке\",\n",
    "        \"char3\": \"Использование авторитетных формулировок\"\n",
    "    }\n",
    "]\n",
    "\n",
    "scenario = \"Ученик не понимает новую тему по математике и стесняется задавать вопросы на уроке\"\n",
    "\n",
    "for style in styles:\n",
    "    chain = teacher_prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"style\": style[\"name\"],\n",
    "        \"style_char1\": style[\"char1\"],\n",
    "        \"style_char2\": style[\"char2\"],\n",
    "        \"style_char3\": style[\"char3\"],\n",
    "        \"scenario\": scenario\n",
    "    })\n",
    "    print(f\"\\nВариант стиля: {style['name']}\\n\")\n",
    "    print(response.content)\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
