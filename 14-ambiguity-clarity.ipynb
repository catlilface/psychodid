{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Устранение неоднозначности и повышение ясности промптов\n",
        "\n",
        "## Обзор\n",
        "\n",
        "Урок посвящён двум важным аспектам промпт-инжиниринга: выявлению и устранению неоднозначности в промптах и приёмам написания более ясных формулировок. Эти навыки напрямую влияют на точность и релевантность ответов модели.\n",
        "\n",
        "## Мотивация\n",
        "\n",
        "Неоднозначный промпт приводит к непредсказуемым или нерелевантным ответам, а нечёткая формулировка — к неточностям. Умение находить и устранять эти проблемы заметно повышает качество работы с ИИ в любых задачах.\n",
        "\n",
        "## Ключевые компоненты\n",
        "\n",
        "1. Выявление неоднозначных промптов.\n",
        "2. Стратегии устранения неоднозначности.\n",
        "3. Приёмы написания ясных промптов.\n",
        "4. Практические примеры и упражнения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Установка окружения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(os.path.join(os.path.dirname(os.getcwd()), \".env\"))\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
        "base_url = os.getenv('BASE_URL')\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", base_url=base_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Выявление неоднозначных промптов\n",
        "\n",
        "Разберём несколько неоднозначных промптов и проанализируем их возможные интерпретации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ambiguous_prompts = [\n",
        "    \"Расскажи про программу.\",\n",
        "    \"Как лучше оценивать?\",\n",
        "    \"Объясни метод.\"\n",
        "]\n",
        "\n",
        "for prompt in ambiguous_prompts:\n",
        "    analysis_prompt = f\"Проанализируй следующий промпт на неоднозначность: «{prompt}». Объясни, почему он неоднозначен, и перечисли возможные интерпретации.\"\n",
        "    print(f\"Промпт: {prompt}\")\n",
        "    print(llm.invoke(analysis_prompt).content)\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Устранение неоднозначности\n",
        "\n",
        "Рассмотрим стратегии устранения неоднозначности с помощью контекста."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resolve_ambiguity(prompt, context):\n",
        "    \"\"\"\n",
        "    Устраняет неоднозначность промпта, добавляя контекст.\n",
        "    \n",
        "    Args:\n",
        "        prompt (str): Исходный неоднозначный промпт.\n",
        "        context (str): Дополнительный контекст.\n",
        "    \n",
        "    Returns:\n",
        "        str: Ответ модели на уточнённый промпт.\n",
        "    \"\"\"\n",
        "    clarified_prompt = f\"{context}\\n\\nС учётом этого контекста, {prompt}\"\n",
        "    return llm.invoke(clarified_prompt).content\n",
        "\n",
        "# Один и тот же промпт — два разных контекста\n",
        "ambiguous_prompt = \"Расскажи про программу.\"\n",
        "contexts = [\n",
        "    \"Ты завуч школы, обсуждающий учебную программу по математике для 8-го класса.\",\n",
        "    \"Ты IT-преподаватель, объясняющий школьнику, что такое компьютерная программа.\"\n",
        "]\n",
        "\n",
        "for context in contexts:\n",
        "    print(f\"Контекст: {context}\")\n",
        "    print(f\"Ответ: {resolve_ambiguity(ambiguous_prompt, context)}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Приёмы написания ясных промптов\n",
        "\n",
        "Посмотрим, как более чёткая формулировка меняет качество ответа модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_prompt_clarity(original_prompt, improved_prompt):\n",
        "    \"\"\"\n",
        "    Сравнивает ответы на нечёткий и улучшенный промпт.\n",
        "    \n",
        "    Args:\n",
        "        original_prompt (str): Исходный нечёткий промпт.\n",
        "        improved_prompt (str): Улучшенная, ясная версия.\n",
        "    \n",
        "    Returns:\n",
        "        tuple: Ответы на оба промпта.\n",
        "    \"\"\"\n",
        "    original_response = llm.invoke(original_prompt).content\n",
        "    improved_response = llm.invoke(improved_prompt).content\n",
        "    return original_response, improved_response\n",
        "\n",
        "# Нечёткий промпт vs ясный\n",
        "original_prompt = \"Как это провести?\"\n",
        "improved_prompt = \"\"\"Составь пошаговую инструкцию для учителя: как провести урок \n",
        "с элементами групповой работы в классе из 25 учеников. Укажи этапы, \n",
        "примерное время на каждый и что нужно подготовить заранее.\"\"\"\n",
        "\n",
        "original_response, improved_response = compare_prompt_clarity(original_prompt, improved_prompt)\n",
        "\n",
        "print(\"Нечёткий промпт:\")\n",
        "print(original_response)\n",
        "print(\"\\nЯсный промпт:\")\n",
        "print(improved_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Структурированные промпты для ясности\n",
        "\n",
        "Структурированные промпты заметно повышают ясность и единообразие ответов модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "structured_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\", \"aspects\", \"tone\"],\n",
        "    template=\"\"\"Проведи анализ темы «{topic}» по следующим аспектам:\n",
        "    1. {{aspects[0]}}\n",
        "    2. {{aspects[1]}}\n",
        "    3. {{aspects[2]}}\n",
        "    \n",
        "    Изложи анализ в {tone} тоне.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Пример: анализ влияния цифровых технологий на школьное образование\n",
        "input_variables = {\n",
        "    \"topic\": \"влияние цифровых технологий на школьное образование\",\n",
        "    \"aspects\": [\"вовлечённость учеников\", \"качество усвоения материала\", \"нагрузка на учителя\"],\n",
        "    \"tone\": \"взвешенном и объективном\"\n",
        "}\n",
        "\n",
        "chain = structured_prompt | llm\n",
        "response = chain.invoke(input_variables).content\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Практическое упражнение: улучшение ясности промптов\n",
        "\n",
        "Потренируемся улучшать нечёткие промпты с помощью самой модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unclear_prompts = [\n",
        "    \"В чём разница?\",\n",
        "    \"Как это работает?\",\n",
        "    \"Почему это важно?\"\n",
        "]\n",
        "\n",
        "def improve_prompt_clarity(unclear_prompt):\n",
        "    \"\"\"\n",
        "    Улучшает ясность нечёткого промпта с помощью модели.\n",
        "    \n",
        "    Args:\n",
        "        unclear_prompt (str): Исходный нечёткий промпт.\n",
        "    \n",
        "    Returns:\n",
        "        str: Улучшенная, конкретная версия промпта.\n",
        "    \"\"\"\n",
        "    improvement_prompt = f\"Следующий промпт нечёткий: «{unclear_prompt}». Предложи более ясную и конкретную версию этого промпта в контексте школьного образования. Выведи только улучшенный промпт, без пояснений.\"\n",
        "    return llm.invoke(improvement_prompt).content\n",
        "\n",
        "for prompt in unclear_prompts:\n",
        "    improved_prompt = improve_prompt_clarity(prompt)\n",
        "    print(f\"Исходный: {prompt}\")\n",
        "    print(f\"Улучшенный: {improved_prompt}\")\n",
        "    print(\"-\" * 50)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
